{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "subsequent-identity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn import metrics\n",
    "from sklearn.impute import MissingIndicator, SimpleImputer\n",
    "from sklearn.preprocessing import  PolynomialFeatures, KBinsDiscretizer, FunctionTransformer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, MaxAbsScaler\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, LabelBinarizer, OrdinalEncoder\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, ElasticNet, Lasso, Ridge\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor, export_graphviz, export_text\n",
    "from sklearn.ensemble import BaggingClassifier, BaggingRegressor,RandomForestClassifier,RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingClassifier,GradientBoostingRegressor, AdaBoostClassifier, AdaBoostRegressor \n",
    "from sklearn.svm import LinearSVC, LinearSVR, SVC, SVR\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "imported-trunk",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
      "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
      "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
      "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
      "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
      "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
      "\n",
      "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
      "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
      "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
      "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
      "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
      "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
      "\n",
      "        V26       V27       V28  Amount  Class  \n",
      "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
      "1  0.125895 -0.008983  0.014724    2.69      0  \n",
      "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
      "3 -0.221929  0.062723  0.061458  123.50      0  \n",
      "4  0.502292  0.219422  0.215153   69.99      0  \n",
      "\n",
      "[5 rows x 31 columns]\n",
      "(284807, 31)\n"
     ]
    }
   ],
   "source": [
    "# Reading and observing data\n",
    "data = pd.read_csv(r\"C:\\Users\\yigit\\AppData\\Local\\Programs\\Python\\Python39\\Scripts\\datasets\\credit card\\creditcard.csv\")\n",
    "print(data.head())\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "banned-belfast",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of Transactions are : 284807\n",
      "Number of Normal Transactions are : 284315\n",
      "Number of fraudulent Transactions are : 492\n",
      "Percentage of fraud Transactions is : 0.17\n"
     ]
    }
   ],
   "source": [
    "# Number of Fraudulent - Normal Transactions\n",
    "total_transactions = len(data)\n",
    "normal = len(data[data.Class == 0])\n",
    "fraudulent = len(data[data.Class == 1])\n",
    "fraud_percentage = round(fraudulent/normal*100, 2)\n",
    "print('Total number of Transactions are : ' + str(total_transactions))\n",
    "print('Number of Normal Transactions are : ' + str(normal))\n",
    "print('Number of fraudulent Transactions are : ' + str(fraudulent))\n",
    "print('Percentage of fraud Transactions is : ' + str(fraud_percentage))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "radical-yellow",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 284807 entries, 0 to 284806\n",
      "Data columns (total 31 columns):\n",
      " #   Column  Non-Null Count   Dtype  \n",
      "---  ------  --------------   -----  \n",
      " 0   Time    284807 non-null  float64\n",
      " 1   V1      284807 non-null  float64\n",
      " 2   V2      284807 non-null  float64\n",
      " 3   V3      284807 non-null  float64\n",
      " 4   V4      284807 non-null  float64\n",
      " 5   V5      284807 non-null  float64\n",
      " 6   V6      284807 non-null  float64\n",
      " 7   V7      284807 non-null  float64\n",
      " 8   V8      284807 non-null  float64\n",
      " 9   V9      284807 non-null  float64\n",
      " 10  V10     284807 non-null  float64\n",
      " 11  V11     284807 non-null  float64\n",
      " 12  V12     284807 non-null  float64\n",
      " 13  V13     284807 non-null  float64\n",
      " 14  V14     284807 non-null  float64\n",
      " 15  V15     284807 non-null  float64\n",
      " 16  V16     284807 non-null  float64\n",
      " 17  V17     284807 non-null  float64\n",
      " 18  V18     284807 non-null  float64\n",
      " 19  V19     284807 non-null  float64\n",
      " 20  V20     284807 non-null  float64\n",
      " 21  V21     284807 non-null  float64\n",
      " 22  V22     284807 non-null  float64\n",
      " 23  V23     284807 non-null  float64\n",
      " 24  V24     284807 non-null  float64\n",
      " 25  V25     284807 non-null  float64\n",
      " 26  V26     284807 non-null  float64\n",
      " 27  V27     284807 non-null  float64\n",
      " 28  V28     284807 non-null  float64\n",
      " 29  Amount  284807 non-null  float64\n",
      " 30  Class   284807 non-null  int64  \n",
      "dtypes: float64(30), int64(1)\n",
      "memory usage: 67.4 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.0, 25691.16)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data.info()\n",
    "\n",
    "min(data['Amount']),max(data['Amount'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "polyphonic-college",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(275663, 30)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scaling 'Amount' column so the values will be similar type\n",
    "sc = StandardScaler()\n",
    "amount = data['Amount'].values\n",
    "data['Amount'] = sc.fit_transform(amount.reshape(-1, 1))\n",
    "# Dropping 'Time' column since it won't make huge effect\n",
    "data.drop(['Time'], axis=1, inplace=True)\n",
    "# Dropping duplicates if there are any\n",
    "data.drop_duplicates(inplace=True)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "centered-appearance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train - Test Split\n",
    "X = data.drop('Class', axis = 1).values\n",
    "y = data['Class'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "guilty-devil",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the Decision Tree model is : 0.9991583957281328\n",
      "F1 score of the Decision Tree model is : 0.7521367521367521\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[68770,    18],\n",
       "       [   40,    88]], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decision Tree\n",
    "DT = DecisionTreeClassifier(max_depth = 4, criterion = 'entropy')\n",
    "DT.fit(X_train, y_train)\n",
    "dt_yhat = DT.predict(X_test)\n",
    "\n",
    "print('Accuracy score of the Decision Tree model is : ' + str(accuracy_score(y_test, dt_yhat)))\n",
    "print('F1 score of the Decision Tree model is : ' + str(f1_score(y_test, dt_yhat)))\n",
    "confusion_matrix(y_test, dt_yhat, labels = [0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "endangered-lover",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the K-Nearest Neighbors model is : 0.999288989494457\n",
      "F1 score of the K-Nearest Neighbors model is : 0.7949790794979079\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "n = 7\n",
    "KNN = KNeighborsClassifier(n_neighbors = n)\n",
    "KNN.fit(X_train, y_train)\n",
    "knn_yhat = KNN.predict(X_test)\n",
    "\n",
    "print('Accuracy score of the K-Nearest Neighbors model is : ' + str(accuracy_score(y_test, knn_yhat)))\n",
    "print('F1 score of the K-Nearest Neighbors model is : ' + str(f1_score(y_test, knn_yhat)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "opposite-syracuse",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the Logistic Regression model is : 0.9989552498694062\n",
      "F1 score of the Logistic Regression model is : 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "lr_yhat = lr.predict(X_test)\n",
    "\n",
    "print('Accuracy score of the Logistic Regression model is : ' + str(accuracy_score(y_test, lr_yhat)))\n",
    "print('F1 score of the Logistic Regression model is : ' + str(f1_score(y_test, lr_yhat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "hired-personal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the Support Vector Machines model is : 0.999318010331418\n",
      "F1 score of the Support Vector Machines model is : 0.7813953488372093\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "svm = SVC()\n",
    "svm.fit(X_train, y_train)\n",
    "svm_yhat = svm.predict(X_test)\n",
    "\n",
    "print('Accuracy score of the Support Vector Machines model is : ' + str(accuracy_score(y_test, svm_yhat)))\n",
    "print('F1 score of the Support Vector Machines model is : ' + str(f1_score(y_test, svm_yhat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bottom-elite",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score of the Random Forest model is : 0.9991583957281328\n",
      "F1 score of the Random Forest model is : 0.7339449541284404\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "rf = RandomForestClassifier(max_depth = 4)\n",
    "rf.fit(X_train, y_train)\n",
    "rf_yhat = rf.predict(X_test)\n",
    "\n",
    "print('Accuracy score of the Random Forest model is : ' + str(accuracy_score(y_test, rf_yhat)))\n",
    "print('F1 score of the Random Forest model is : ' + str(f1_score(y_test, rf_yhat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "original-macedonia",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\yigit\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:35:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy score of the XGBoost model is : 0.999506645771664\n",
      "F1 score of the XGBoost model is : 0.8495575221238937\n"
     ]
    }
   ],
   "source": [
    "# XGBoost\n",
    "xgb = XGBClassifier(max_depth = 4)\n",
    "xgb.fit(X_train, y_train)\n",
    "xgb_yhat = xgb.predict(X_test)\n",
    "\n",
    "print('Accuracy score of the XGBoost model is : ' + str(accuracy_score(y_test, xgb_yhat)))\n",
    "print('F1 score of the XGBoost model is : ' + str(f1_score(y_test, xgb_yhat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "threatened-pressure",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
